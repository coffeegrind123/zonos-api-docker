# ğŸ”„ Updated Model Loading Behavior

## âœ… **NEW BEHAVIOR IMPLEMENTED**

### **Single Model Loading Strategy**
- **âœ… Default Model**: Loads `Zyphra/Zonos-v0.1-transformer` on startup
- **âœ… On-Demand Switching**: Unloads current model and loads requested model when different model is requested
- **âœ… Memory Efficient**: Only one model loaded at a time, frees GPU memory when switching
- **âœ… Fast First Request**: Default model ready immediately, no loading delay

### **Model Availability Status**
```python
available_models = {
    "Zyphra/Zonos-v0.1-transformer": {
        "status": "available", 
        "supports_deepspeed": True
    },
    "Zyphra/Zonos-v0.1-hybrid": {
        "status": "backbone_incompatible",  # Currently not working
        "supports_deepspeed": False
    }
}
```

## ğŸ”„ **Loading Flow**

### **Startup**
1. Service initializes with optimizations
2. Loads default transformer model with DeepSpeed (if enabled)
3. Ready to serve requests immediately

### **Request Flow**
1. **Same Model Request**: Uses already-loaded model (fast)
2. **Different Model Request**: 
   - Logs: `ğŸ”„ Switching from [current] to [requested]`
   - Logs: `ğŸ“¤ Unloading [current model]`
   - Frees GPU memory with `torch.cuda.empty_cache()`
   - Logs: `ğŸ“¥ Loading requested model: [new model]`
   - Applies DeepSpeed if supported and enabled
   - Ready to serve with new model

## ğŸ“Š **Expected Log Behavior**

### **Startup (Default Model)**
```
ğŸš€ Initializing Zonos TTS Service with performance optimizations
âš™ï¸ GPU preference: fastest
ğŸ¯ Selected device: cuda:0
ğŸš€ DeepSpeed acceleration available (optional)
ğŸš€ DeepSpeed acceleration enabled
ğŸ“¦ Loading default model on startup: Zyphra/Zonos-v0.1-transformer
ğŸ“¥ Loading model: Zyphra/Zonos-v0.1-transformer
ğŸ”§ Loading Zyphra/Zonos-v0.1-transformer with PyTorch
ğŸš€ Applying DeepSpeed optimization to Zyphra/Zonos-v0.1-transformer
âœ… Successfully loaded Zyphra/Zonos-v0.1-transformer with DeepSpeed optimization
ğŸ‰ Successfully loaded default model: Zyphra/Zonos-v0.1-transformer
```

### **Same Model Request (Fast)**
```
Using model: Zyphra/Zonos-v0.1-transformer
âœ… Model Zyphra/Zonos-v0.1-transformer already loaded
```

### **Model Switch Request**
```
ğŸ”„ Switching from Zyphra/Zonos-v0.1-transformer to Zyphra/Zonos-v0.1-hybrid
ğŸ“¤ Unloading Zyphra/Zonos-v0.1-transformer
ğŸ“¥ Loading requested model: Zyphra/Zonos-v0.1-hybrid
ğŸ“¥ Loading model: Zyphra/Zonos-v0.1-hybrid
ğŸ”§ Loading Zyphra/Zonos-v0.1-hybrid with PyTorch
âœ… Successfully loaded Zyphra/Zonos-v0.1-hybrid with standard PyTorch
Using model: Zyphra/Zonos-v0.1-hybrid
```

## âœ… **Benefits**

### **Memory Efficiency**
- Only one model in GPU memory at a time
- Proper cleanup with `torch.cuda.empty_cache()`
- No memory leaks from accumulated models

### **Performance**
- **Fast startup**: Default model loaded immediately
- **Fast same-model requests**: No loading delay
- **Smart switching**: Only loads when needed

### **Flexibility**
- Supports switching between all available models
- Handles model compatibility (hybrid currently disabled)
- Maintains DeepSpeed optimization where supported

### **User Experience**
- **First request**: Fast (model pre-loaded)
- **Same model requests**: Instant
- **Model switching**: ~15-30 seconds with clear progress logging
- **Error handling**: Clear messages if model unavailable

## ğŸ¯ **Model Support Status**

- **âœ… Transformer Model**: Fully working with DeepSpeed acceleration
- **âš ï¸ Hybrid Model**: Temporarily disabled due to backbone incompatibility
- **ğŸ”® Future**: Will re-enable hybrid when backbone supports it

## ğŸš€ **API Behavior**

- **Default requests**: Use transformer model (fast)
- **Explicit model requests**: Switch to requested model if available
- **Invalid model requests**: Return error with available models list
- **Model aliases**: Support both `zonos-v0.1-transformer` and `Zyphra/Zonos-v0.1-transformer`

The system now provides optimal memory usage while maintaining fast response times for the common case (default model) and supporting model switching when needed.